{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "first-funds",
   "metadata": {},
   "source": [
    "# NETFLIX MOVIE RATE PREDICTION USING GAUSSIAN MIXTURES "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-underground",
   "metadata": {},
   "source": [
    "# MOTIVATION: \n",
    "* The input is ratings by $n$ users of $d$ movies. However, the data is incomplete in the sense that each movie has not been rated by every user although we assume that each movie has been rated by at least one user. Our task is to fill in the missing ratings. In this case we will use an EM algorithm applied to a Gaussian mixture.\n",
    "* <span style='color:blue'>The present notebook contains exclussively the parts of the code that I developed for the fulfillment of the project. Functions to upload and prepare the data were pre-programmed by the organizers of the course and provided to us.</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-black",
   "metadata": {},
   "source": [
    "# PREAMBLE: \n",
    "\n",
    "* ## The input will be denoted as $X$, which is a $(n,d)$ array and the $i$-th row, $X[i,:]$ is the rating made by the $i$-th user. The missing ratings are in our case set to $0$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-prevention",
   "metadata": {},
   "source": [
    "---\n",
    "# DEFINING THE GAUSSIAN MIXTURE:\n",
    "We will assume that, as far as the rating is concerned, the $n$ users may be divide into $K$ clusters. Each cluster has a probability $p_j$ to occur  and within each cluster, say the $j$-th cluster, we will assume that the probability for a user to provide the rating $x=(x_1,\\cdots,x_d)$ follows a Gaussian distribution with mean $\\mu_j\\in\\mathbb R^d$ and variance $\\sigma_j\\in\\mathbb R$, that is: \n",
    "## $$p(x|j) = \\frac{1}{\\sqrt[d]{2\\pi \\sigma_j^2}}\\, e^{-\\frac{\\parallel x-\\mu_j\\parallel^2}{2 \\sigma_j^2}}=:\\mathcal N\\left(x;\\mu_j,\\sigma_j\\right)$$\n",
    "where $p(x|j)$ is the conditional probability for having the rating $x$ given that we know it comes from the $j$-th cluster. Thus, the probability for having the rating $x$, disregarding from which cluster that rating has been made, is \n",
    "## $$p(x)=\\sum_{j= 1}^K p(x|j)\\,p_j = \\sum_{j=1}^K p_j \\mathcal N\\left(x;\\mu_j,\\sigma_j\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-alias",
   "metadata": {},
   "source": [
    "# POSTERIOR PROBABILITY:\n",
    "Using the Bayes's rule we find that \n",
    "## $$p(j|x) = \\frac{p(x|j)\\,p_j}{p(x)}$$ \n",
    "where $p(j|x)$ is the probability that the rating $x$ has been made by an user from the $j$-th cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-paint",
   "metadata": {},
   "source": [
    "# OPTIMIZATION:\n",
    "Given a set of ratings $S=\\left\\{x^{(1)},\\cdots,x^{(n)}\\right\\}$ (possibly with missing data), the probability for obtaining the whole set, called the likelihood, is \n",
    "## $$ p(S)= \\prod_{i=1}^n p\\left(x^{(i)}\\right)$$ \n",
    "where $p\\left(x^{(i)}\\right) = \\sum_j p_j \\mathcal N\\left(x^{(i)}_{c_i};\\mu_{j,c_i},\\sigma_j\\right)$ and $x^{(i)}_{c_i}$ and $\\mu_{j,c_i}$ contain only the  components where $x^{(i)}$ has not missing data. \n",
    "Our goal is to find the parameters $\\mu_j$, $\\sigma_j$ and $p_j$ that maximize the likelihood $p(S)$ \n",
    "or equivalently, \n",
    "## $$\\ln p(S) = \\sum_{i=1}^n \\ln p\\left(x^{(i)}\\right)$$\n",
    "Maximizing this function is a very hard task given the complicated dependence on its parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-client",
   "metadata": {},
   "source": [
    "## MAXIMIZING A LOWER BOUND OF $\\ln p(S)$:\n",
    "Instead, we will maximize a lower bound of $\\ln p(S)$.  By doing so, we make sure to push upwards the true likelihood.  \n",
    "A lower bound of $\\ln P(S)$:\n",
    "The so-called Jensen's inequality states that for non-negative $q_1,\\cdots,q_n$ and $y_1,\\cdots,y_n$ with $\\sum_a q_a = 1$ it holds that \n",
    "## $$\\sum_a q_a \\ln y_a\\leq \\ln\\left(\\sum_a q_a y_a\\right)$$\n",
    "For fixed $i$, let $p(j|i):= p\\left(j|x^{(i)}\\right)$, that is: the probability that the cluster is the $j$-th one, given the rating $x^{(i)}$. Then, taking $y_j := \\frac{p_j\\,\\mathcal N\\left(x^{(i)}_{c_i};\\mu_{j,c_i},\\sigma_j\\right)}{p(j|i)}$ and $q_j := p(j|i)$ the Jensen's inequality states that \n",
    "## $$\\sum_{j=1}^K p(j|i) \\ln \\frac{p_j\\,\\mathcal N\\left(x^{(i)}_{c_i};\\mu_{j,c_i},\\sigma_j\\right)}{p(j|i)} \\leq \\ln\\left(\\sum_{j=1}^K p_j\\,\\mathcal N\\left(x^{(i)}_{c_i};\\mu_{j,c_i},\\sigma_j\\right)\\right) = \\ln p\\left( x^{(i)}\\right)$$ \n",
    "Thus, \n",
    "## $$\\hat l := \\sum_{i=1}^n\\sum_{j=1}^K p(j|i) \\ln \\frac{p_j\\,\\mathcal N\\left(x^{(i)}_{c_i};\\mu_{j,c_i},\\sigma_j\\right)}{p(j|i)} \\leq \\ln P(S)$$ \n",
    "It turns out that maximizing the lower bound $\\hat l$ is much simpler, at least to find a local maximum for it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-thumb",
   "metadata": {},
   "source": [
    "---\n",
    "# THE EM ALGORITHM (for maximizing the lower bound $\\hat l$):\n",
    "The EM algorithm guarantees convergence to a local maximum. It is defined as follows:\n",
    "\n",
    "* **Step 0**: Randomly initialize the parameters $\\mu_j$, $\\sigma_j$ and $p_j$\n",
    "Then iterate the following two steps until convergence:\n",
    "\n",
    "* **E-step:** set $p(j|i)$ as \n",
    "\n",
    "## $$p(j|i):= \\frac{p_j \\mathcal N\\left(x^{(i)}_{c_i};\\mu_{j,c_i},\\sigma_j\\right)}{\\sum_{l=1}^K p_l \\mathcal N\\left(x^{(i)}_{c_i};\\mu_{l,c_i},\\sigma_l\\right)}$$ \n",
    "    \n",
    "    (Note that this is the posterior probability corresponding to the current parameters $(\\mu_j,\\sigma_j,p_j)$. This expression also follows from the vanishing of the gradient of $\\hat l$ with respect to $p(j|i)$, subject to the constratint $\\sum_{j=1}^K p(j|i)=1$.)\n",
    "    \n",
    "* **M-step**: do the following updates: \n",
    "\n",
    "## $$ p_j \\leftarrow \\frac{1}{n} \\sum_{i=1}^n p(j|i)$$\n",
    "## $$\\left(\\mu_j\\right)_l \\leftarrow \\frac{1}{\\sum_{i'=1}^n \\delta_{l,c_{i'}} p(j|i')} \\sum_{i=1}^n p(j|i)\\delta_{l,c_i}\\left(x^{(i)}\\right)_l$$\n",
    "##  $$\\sigma_j^2 \\leftarrow \\frac{\\sum_{i= 1}^n p(j|i) \\parallel x^{(i)}_{c_i}-\\mu_{j,c_i}\\parallel^2}{\\sum_{i'=1}^n p(j|i') \\,| c_{i'}|}$$                                                   \n",
    "\n",
    "Where $()_l$ denotes the $l$-th  component, $\\delta_{l,c_i}$ is $1$ if the $l$-th component is not missing, $0$ otherwise, and $|c_i|$ denotes the number of not missing components for the rating $x^{(i)}$.\n",
    "(These updates follow from the vanishing of the gradient of $\\hat l$ with respect to $(\\mu_j,\\sigma_j,p_j)$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-growth",
   "metadata": {},
   "source": [
    "# PREDICTING THE MISSING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-adolescent",
   "metadata": {},
   "source": [
    "Once we have optimized the mixture parameters $(\\mu_j,\\sigma_j,p_j)$, we may compute the missing data as the weighted average of the means $\\mu_j$ according to the posterior probability. \n",
    "\n",
    "More precisely, suppose that the $i$-th user has not rated the $m$-th movie. Since the probability for the $i$-th user to belong to the $j$-th cluster is $p(j|i)$ and the mean \"rating\" corresponding to that cluster is $\\mu_j$, we may estimate the missing rate as \n",
    "\n",
    "## $$\\hat x_{im} = \\sum_{j= 1}^K p(j|i) \\, \\left(\\mu_j\\right)_m$$\n",
    "\n",
    "where $\\left(\\mu_j\\right)_m$ denotes the $m$-th component of $\\mu_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-neutral",
   "metadata": {},
   "source": [
    "---\n",
    "# EM ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-providence",
   "metadata": {},
   "source": [
    "## Initialize the parameters\n",
    "A similar version of this function was provided to us by the course organizers. I have modified it to adapt it to the present notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "promising-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_param(X,K=10,seed=0):\n",
    "    \"\"\"\n",
    "    Initializes the Gaussain mixture parameters\n",
    "    \n",
    "    Args:\n",
    "        X : (n , d) array containing the data\n",
    "        K : int, number of Gaussian clusters\n",
    "        seed : int, seed for the random generation, default : 0\n",
    "    \n",
    "    Returns:\n",
    "        mixture : tuple (mu,var,p) -- initial mixture parameters -- \n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    n,_ = X.shape\n",
    "    p = np.ones(K)/K\n",
    "    \n",
    "    # select K random points as initial means\n",
    "    mu = X[np.random.choice(n,K,replace=False)]\n",
    "    # computing variances\n",
    "    var = np.zeros(K)\n",
    "    for j in range(K):\n",
    "        var[j]=((X-mu[j])**2).mean() \n",
    "    \n",
    "    return GaussianMixture(mu,var,p)\n",
    "\"\"\"\n",
    "The function GaussianMixture generates the tuple (mu,var,p) and was provided for usâˆ« \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-strip",
   "metadata": {},
   "source": [
    "## E-step  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dedicated-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estep(X,mixture):\n",
    "    \"\"\"\n",
    "    Estimates the posterior probability\n",
    "    \n",
    "    Args:\n",
    "        X : (n, d) np.array containing the ratings\n",
    "        mixture : GaussianMixture(mu,var,p) -- current mixture parameters --\n",
    "    Returns: \n",
    "        post : (n , K) np.array containing the posterior probabilities : \n",
    "                       post[i,j] = p(j|i)\n",
    "        logl : float, the log-likelihood -- ln(p(S)) -- for X, given the current parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    mu = mixture.mu # (K , d) np.array\n",
    "    var = mixture.var # (K, ) np.array\n",
    "    p = mixture.p # (K, ) np.array\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    K = mu.shape[0]\n",
    "    \n",
    "    post = np.zeros((n,K))\n",
    "    logl = 0\n",
    "    for i in range(n):\n",
    "        C_i = X[i,:] != 0 # not missing components\n",
    "        d_i = np.sum(C_i)\n",
    "        # argument of the Gaussian \n",
    "        exp_arg = ((np.tile(X[i,C_i],(K,1))-mu[:,C_i])**2).sum(axis=1)\n",
    "        exp_arg = exp_arg/(2*var)\n",
    "        # log(N(x;mu,var))\n",
    "        \"\"\"\n",
    "        To avoid log(0) evaluations, we add a very small number to p\n",
    "        \"\"\"\n",
    "        logN_i = np.log(p+10**(-16)) - d_i*np.log(2*np.pi*var)/2 - exp_arg \n",
    "        logN_max_i = logN_i.max() \n",
    "        # log(post[i,:]) \n",
    "        \"\"\"\n",
    "        For numerical stability, we substract the max value of\n",
    "        logN_i. The substraction cancels out in the expression below\n",
    "        \"\"\"\n",
    "        log_posti = logN_i - logN_max_i - logsumexp(logN_i-logN_max_i)\n",
    "        # post[i,:]\n",
    "        post_i = np.exp(log_posti)\n",
    "        logl = logl + post_i @ (logN_i - log_posti)\n",
    "        post[i,:] = post_i\n",
    "    \n",
    "    return post, logl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-usage",
   "metadata": {},
   "source": [
    "## M-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indoor-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mstep(X,mixture,post,\n",
    "         min_var = 0.25):\n",
    "    \"\"\"\n",
    "    Updates the mixture parameters\n",
    "    \n",
    "    Args:\n",
    "        X : (n, d) np.array containing the ratings\n",
    "        mixture : GaussianMixture(mu,var,p) -- current mixture parameters --\n",
    "        post : (n , K) np.array containing the posterior probabilities : \n",
    "                       post[i,j] = p(j|i)\n",
    "        min_var : float, minimum variance to avoid too narrow Gaussians  \n",
    "        \n",
    "    Returns: \n",
    "        mixture : GaussMix(mu,var,p) -- updated mixture parameters --\n",
    "    \"\"\"\n",
    "    \n",
    "    n , d = X.shape \n",
    "    K = len(mixture.p)\n",
    "    p = post.sum(axis=0)/n # sum_i P(j|i)/n\n",
    "    mu = mixture.mu # (k,d)\n",
    "    var = mixture.var \n",
    "    delta = 1*(X != 0)  # (n,d)\n",
    "    for j in range(K):\n",
    "        # updating mu\n",
    "        mu_numerator = post[:,j] @ X\n",
    "        mu_denominator = post[:,j] @ delta\n",
    "        \"\"\"\n",
    "        In order to avoid updating components of mu \n",
    "        corresponding to too few ratings or very unlikely ratings \n",
    "        from the j-th cluster, \n",
    "        we demand that \\sum_i delta_{l,c_i} p(j|i) >= 1 \n",
    "        \"\"\"\n",
    "        update_indices = mu_denominator >= 1\n",
    "        mu[j,update_indices] = mu_numerator[update_indices] / mu_denominator[update_indices]\n",
    "        # updating var\n",
    "        var[j] = post[:,j] @ ((X-np.tile(mu[j,:],(n,1))*delta)**2).sum(axis=1) / mu_denominator.sum()\n",
    "        if var[j] <= min_var:\n",
    "            var[j] = min_var\n",
    "    return GaussianMixture(mu, var, p) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-retail",
   "metadata": {},
   "source": [
    "# COMPLETEING THE RATING MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alleged-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_matrix(X,mixture):\n",
    "    \"\"\"\n",
    "    Completes the rating matrix\n",
    "    \n",
    "    Args:\n",
    "        X : (n, d) np.array containing the (incomplete) ratings\n",
    "        mixture : GaussMix(mu,var,p) -- optimized mixture parameters --\n",
    "    \n",
    "    Returns:\n",
    "        X : (n, d) np.array containing the complete ratings\n",
    "    \"\"\"\n",
    "    \n",
    "    p = mixture.p # (K,)\n",
    "    mu = mixture.mu # (K,d) \n",
    "    var = mixture.var # (K,)\n",
    "    n , d = X.shape \n",
    "    X_pred = np.zeros((n,d))\n",
    "    K = len(p)\n",
    "    for i in range(n):\n",
    "        C_i = X[i,:] != 0 # not missing components\n",
    "        d_i = np.sum(C_i)\n",
    "        # argument of the Gaussian \n",
    "        exp_arg = ((np.tile(X[i,C_i],(K,1))-mu[:,C_i])**2).sum(axis=1)\n",
    "        exp_arg = exp_arg/(2*var)\n",
    "        # log(N(x;mu,var))\n",
    "        \"\"\"\n",
    "        To avoid log(0) evaluations, we add a very small number to p\n",
    "        \"\"\"\n",
    "        logN_i = np.log(p+10**(-16)) - d_i*np.log(2*np.pi*var)/2 - exp_arg \n",
    "        logN_max_i = logN_i.max() \n",
    "        # log(post[i,:]) \n",
    "        \"\"\"\n",
    "        For numerical stability, we substract the max value of\n",
    "        logN_i. The substraction cancels out in the expression below\n",
    "        \"\"\"\n",
    "        log_posti = logN_i - logN_max_i - logsumexp(logN_i-logN_max_i)\n",
    "        # post[i,:]\n",
    "        post_i = np.exp(log_posti)\n",
    "        unrated_entries = np.logical_not(C_i)\n",
    "        wieghted_mu = post_i @ mu[:,unrated_entries]\n",
    "        X_pred[i,unrated_entries] = wieghted_mu\n",
    "    \n",
    "    return X+X_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-minneapolis",
   "metadata": {},
   "source": [
    "# CALLING THE EM ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brazilian-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(X,K=10,seed=0):\n",
    "    \"\"\"\n",
    "    Runs the EM algorithm\n",
    "    \n",
    "    Args:\n",
    "        X : (n , d) array containing the data\n",
    "        K : int, number of Gaussian clusters\n",
    "        seed : int, seed for the random generation, default : 0\n",
    "    \n",
    "    Returns: \n",
    "        mixture : GaussianMixture(mu,var,p) -- optimized mixture parameters --\n",
    "        logl : list containing the log-likelihoods for all the iterations \n",
    "    \"\"\"\n",
    "    \n",
    "    # Initializing the mixture parameters\n",
    "    mixture = initial_param(X,K=K,seed=seed)\n",
    "    \n",
    "    logl_old = None\n",
    "    logl_new = None\n",
    "    \n",
    "    logl = []\n",
    "    \n",
    "    # EM algorithm\n",
    "    \n",
    "    while (logl_old is None or (logl_new-logl_old >= 10**(-6)*np.abs(logl_new))):\n",
    "        logl_old = logl_new\n",
    "        # E-step\n",
    "        post, logl_new = estep(X,mixture)\n",
    "        # M-step\n",
    "        mixture = mstep(X,mixture,post)\n",
    "        \n",
    "        if logl_new is not None:\n",
    "            logl.append(logl_new)\n",
    "    \n",
    "    return mixture, logl\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-guard",
   "metadata": {},
   "source": [
    "## Plotting the log-likelihood of the mixture as a function of the EM algorithm iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "understanding-knowing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('xtick',labelsize = 15)\n",
    "plt.rc('ytick',labelsize = 15)\n",
    "plt.plot(range(1,len(logl)+1),logl)\n",
    "plt.xlabel('iterations', fontsize = 20)\n",
    "plt.ylabel('$\\ln (\\hat l)$', fontsize = 20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
